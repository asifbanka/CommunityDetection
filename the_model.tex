A \emph{social network} consists of a set of social actors and a set of ties 
between them. A social network is modeled as a graph which may be directed 
or undirected. In this paper, we deal with social networks that are modeled as undirected 
graphs. In the context of community detection in social networks, we make 
the following assumptions. 

Our first assumption is that we know what the network at hand represents. That is, 
we have a sense of context about the network. The network could represent 
friendships as in the Facebook network; co-authorships as in the DBLP network; 
it could be a network of professionals such as LinkedIn, or a network of movie 
lovers such as IMDB. Secondly, we assume that we know what is it that constitutes 
a community within the network. This is crucial because, for one, we do not 
formally define what a community is. We take it as being given as part of the 
input specification. While this may appear as an artifice, in many real-life situations 
where we are required to find communities, we do in fact know what 
it is that we are searching for. For example, we might want to find the set of 
people with a given political leaning, or a set of people who love a particular 
genre of movie, or a set of people with a specific skill-set and experience. 
In each of these cases, we have a sense of what it is that is required to be found. 

In broad brush-strokes, this is how our algorithm works.  It requires that we know
some members from each community that we are aiming to discover. We call these members 
\emph{seed nodes}. A seed node can belong to several communitites and our algorithm 
actually finds out overlapping communities in the network. The algorithm uses the 
partial community information and propagates it to the other nodes of the network 
by simulating a random walk from non-seed nodes to the set of seed nodes. 

Suppose that $x_1, \ldots, x_s$ are the seed nodes in the network and that a random walk starting at 
a non-seed node~$u$ reaches these nodes with probabilities $p_1, \ldots, p_s$. If out 
of these~$s$ seed nodes, $x_{i_1}, \ldots, x_{i_r}$ belong to a community~$C$, then 
the algorithm assigns a probability of $\sum_{j = 1}^r p_{i_j}$ for the event 
that~$u$ belongs to~$C$. For each community, we can now assign a probability for 
the event that~$u$ belongs to it. The communities that the algorithm 
assigns~$u$ are those for which the probabilities exceed a certain threshold. 

The random walk can be represented by a transition matrix and the walk itself can be simulated 
by multiplying this matrix with itself repeatedly. This, however, takes $O(n^3)$
time, where~$n$ is the number of nodes in the network. One of the contributions of 
this paper is to show how this can be reduced to solving a set of Laplacian system 
of linear equations (one set per seed node), which by the work of Speilman and 
Teng~\cite{Vis13} can be done in $O(m \log n)$ time, where~$m$ is the number of edges
in the graph. We assume that our networks are sparse in the sense that $m = O(n)$, 
so that the running time of our algorithm can  be bounded by $O(s n \log n)$.    
        
\subsection{Absorbing Markov Chains and Random Walks}
We now provide a formal description of our model. We assume that our network 
is a simple undirected graph $G = (V,E)$ with~$n$ nodes and~$m$ edges, where $m = O(n)$.
We also know that there are~$k$ communities which may overlap in an arbitrary fashion.
In practical situations, we have~$k \ll n$. 
Moreover, we have some partial information about each community in that we know
$\log n$ members of each community. Call such members of the network \emph{seed nodes} 
and the remaining nodes \emph{non-seed nodes}. Together, we know the community information 
of $k \cdot \log n$ seed nodes. The community information of a node~$u$ is represented 
by a $1 \times k$ vector called the \emph{belonging vector} of~$u$, denoted 
by~$\bvect (u) = (\beta_{u, 1}, \ldots, \beta_{u, k})$. The entry $\beta_{u, i}$ 
of the belonging vector represents the probability that node~$u$ belongs to community~$i$.  
We point out that $\sum_{i = 1}^k \beta_{u, i}$ need not be~$1$. An example of this situation 
is when~$u$ belongs to multiple communities with probability~$1$.
The objective is to find out the belonging vectors of all non-seed nodes. 

To model our random walk, we define an $n \times n$ transition matrix $\mat{P}$ 
as follows. We first assume that the nodes of~$G$ are ordered as 
$u_1, \ldots, u_{n - s}, x_{1}, \ldots, x_{s}$, where $u_1, \ldots, u_{n - s}$
represent the non-seed nodes of the network and $x_1, \ldots, x_s$, the seed nodes.
For a non-seed node~$u$:
\begin{equation}\label{eqn:defining_prob_nonseed}
	\mat{P}(u, z) = \left \{ 
							\begin{array}{ll}
								\frac{1}{\deg (u)} & \mbox{ if } \{u, z\} \in E(G) \\
								0			& \mbox{ otherwise.}
							\end{array}
						\right.
\end{equation}
Note that the sum of the entries of row~$u$ is~$1$. 
For a seed node~$x$, 
\begin{equation}\label{eqn:defining_prob_seed}
	\mat{P}(x,z) = 	\left \{ 
						\begin{array}{ll}
							1 & \mbox{if $z = x$} \\
							0 & \mbox{if $z \neq x$.}
						\end{array}
					\right.
\end{equation}

It is usual to write the transition matrix $\mat{P}$ in the following canonical form:
\begin{equation}\label{eqn:canonical_form_P}
	\mat{P} = 	\left [ \begin{array}{ll}
						\mat{Q}  & \mat{R} \\
						 \mat{0}_{s \times (n - s)} & \mat{I}_{s \times s}
						\end{array}
				\right ],
\end{equation}
where~$\mat{Q}$ is the $(n - s) \times (n - s)$ sub-matrix that represents the transition 
from non-seed nodes to non-seed nodes; $\mat{R}$ is the $(n - s) \times s$ sub-matrix 
that represents the transition from non-seed nodes to seed nodes. The $s \times s$ identity 
matrix $\mat{I}$ represents the fact that once a seed node is reached, one cannot transition away 
from it. Here $\mat{0}_{s \times (n - s)}$ represents an $s \times (n - s)$ matrix of zeros. 
Since each row of $\mat{P}$ sums up to~$1$, this matrix is stochastic.

It is well-known that such a stochastic matrix represents, what is known as, an 
absorbing Markov chain (see, for example, Chapter~11 of Grinstead and Snell~\cite{GS98}).  
A Markov chain is called \emph{absorbing} if it satisfies two conditions. 
It must have at least one absorbing state~$i$, where state~$i$ is defined 
to be absorbing if and only if $\mat{P}(i,i) = 1$ and $\mat{P}(i, j) = 0$ 
for all $j \neq i$. Secondly, it must be possible to transition from every state to 
    some absorbing state (perhaps in multiple steps). 

The transition matrix $\mat{P}$ that we defined via equations~(\ref{eqn:defining_prob_nonseed}) 
and~(\ref{eqn:defining_prob_seed}) satisfy these two properties. To see this, note that 
the transition matrix implicitly defines an arc-weighted  directed graph on the nodes 
of the network. Call this directed graph $G_{\mat{P}}$. For non-seed nodes~$u$ and~$v$ that 
are connected by an edge in the network, there exist two arcs $(u, v)$ and $(v, u)$ 
in $G_{\mat{P}}$ with weights $1/\deg (u)$ and $1/ \deg (v)$, respectively.
If $x$ is a seed node with $p$ non-seed neighbors 
$u_1, \ldots, u_p$, then the edges~$\{u_i, x\}$ in~$G$, for $1 \leq i \leq p$, 
are represented by arcs~$(u_i, x)$ (with weight $1 / \deg (u_i)$) in $G_{\mat{P}}$. 
In addition, $x$ has self-loop with weight~$1$. It is worthwhile to note 
that if two seed nodes are adjacent in~$G$, then the corresponding edge does not have a 
directed counterpart in $G_{\mat{P}}$.  

Now from the theory of Markov chains, the state of the system after a $r$-step transition 
is given by the matrix product $\mat{P}^r$. Moreover, $\mat{P}^r (u, v)$ may be interpreted 
as the probability that a random walk starting at node~$u$ will end up at node~$v$ 
after~$r$ steps. Since the underlying network is connected, every non-seed node can reach a seed
node by some path and such a dipath continues to exist in $D_{\mat{P}}$. This shows that $D_{\mat{P}}$
is indeed an absorbing Markov chain. An easy property of such Markov chains is the following:
\begin{equation}\label{exp:rth_product_of_P}
	\mat{P}^r = \left [ \begin{array}{ll}
						\mat{Q}^r  					& \sum_{i = 0}^{r - 1}\mat{Q}^i \cdot \mat{R} \\
						 \mat{0}_{s \times (n - s)} & \mat{I}_{s \times s}
						\end{array}
				\right ].
\end{equation}  
It can be shown that $\lim_{r \to \infty} \mat{Q}^{r} = \mat{0}$ and that 
the series $\sum_{r = 0}^{\infty} \mat{Q}^{r}$ actually converges to 
$(\mat{I} - \mat{Q})^{-1}$. This matrix series is called the \emph{fundamental matrix}
of the absorbing Markov chain and is denoted by $\mat{N}$. 

We summarize some of the properties of an absorbing Markov chain. 
\begin{proposition}\label{prop:limiting_Q}
	Let $\mat{P}$ be the $n \times n$ transition matrix that defines an absorbing Markov chain
	and suppose that $\mat{P}$ is in the canonical form specified by equation~(\ref{eqn:canonical_form_P}). 
	Then
	\begin{enumerate}
		\item $\lim_{r \to \infty} \mat{Q} = \mat{0}_{(n - s) \times (n - s)}$.
		\item $\sum_{r = 0}^{\infty} \mat{Q}^r \cdot \mat{R} = (\mat{I} - \mat{Q})^{-1} \cdot \mat{R}$.
	\end{enumerate} 
\end{proposition}

We wish to determine the matrix $\mat{N} \mat{R}$: the entry $(u, x)$ of this 
matrix is the probability that a random walk starting at~$u$ ends up at the seed 
node~$x$. Once we have determined this matrix, the belonging vector of $u$ can 
be computed as:
\begin{equation}\label{eqn:belonging_vector}
	\beta(u) = \sum_{i = 1}^{s} (\mat{N} \mat{R}) (u, x_i) \cdot \beta(x_i).
\end{equation}
If we compute $\mat{N}$ by first computing the inverse $(\mat{I} - \mat{Q})^{-1}$
and then multiplying the result by $\mat{R}$, we taken time $O(n^3)$. In the 
next subsection, we show how to reduce this problem to that of solving a 
Laplacian system of linear equations which takes time $O(m \log n)$, where $m$
the number of edges. 

\subsection{Symmetric Diagonally Dominant Linear Systems}

An $n \times n$ matrix $\mat{A} = [a_{ij}]$ is \emph{diagonally dominant} if 
\[
	|a_{ii}| \geq \sum_{j \neq i} {|a_{ij}|} \mbox{ for all } i = 1, \ldots, n.
\] 
A matrix is \emph{symmetric diagonally dominant (SDD)} if, in addition to the above, 
it is symmetric. For more information about matrices and matrix computations, 
see the texbooks by Golub and Van Loan~\cite{GvL13} and Horn and Johnson~\cite{HJ13}. 

An example of a symmetric, diagonally dominant matrix is the graph Laplacian. 
Given an unweighted, undirected graph~$G$, the \emph{Laplacian} of $G$ 
is defined to be 
\[
\mat{L}_G = \mat{D}_G - \mat{A}_G,
\] 
where $\mat{A}_G$ is the adjacency matrix of the graph~$G$ and $\mat{D}_G$ 
is the diagonal matrix of vertex degrees. This definition extends 
to weighted graphs. A weighted graph $G = (V, E)$ has an associated weight function 
$w \colon V \times V \to \R$ which satisfies the conditions: 
\begin{inparaenum}[(1)]
	\item $w(u, v) = w(v, u)$;  
	\item $w(u, v) \geq 0$; and, 
	\item if $\{u, v\} \notin E$ then $w(u, v) = 0$. 
\end{inparaenum}
In the context of weighted graphs, the degree~$\deg_G (u)$ of a vertex~$u$ is defined to be 
\[\label{eqn:weighted_degree}
	\deg_G (u) = \sum_{v \in V} w(u, v). 
\] 
The adjacency matrix $\mat{A}_{G}$ is defined as:
\[\label{eqn:weighted_adj_matrix}
	\mat{A}_{G}(u, v) = w(u, v),
\]
and the Laplacian is defined as before as: 
\[\label{eqn:weighted_laplacian}
	\mat{L}_G = \mat{D}_G - \mat{A}_G,
\]
where $\mat{D}_G$ is the diagonal matrix of vertex degrees in the weighted graph~$G$.

A symmetric, diagonally dominant (SDD) system of linear equations is a system of 
equations of the form:
\[
	\mat{A} \cdot \vect{x} = \vect{b},
\]
where $\mat{A}$ is an SDD matrix, $\vect{x} = \trans{(x_1, \ldots, x_n)}$ 
is a vector of unknowns, and $\vect{b} = \trans{(b_1, \ldots, b_n)}$ is a vector of constants. 
There is near-linear time algorithm for solving such a system of linear equations 
and this result is crucial to the analysis of the running time of our algorithm. 

The solution of $n \times n$ system of linear equations takes $O(n^3)$ time 
if one uses Gaussian elimination. \texttt{More stuff here on sparse systems ...}
Speilman and Teng made a seminal contribution in this direction and 
showed that SDD linear systems can be solved in nearly-linear 
time~\cite{ST04,EEST05,ST08}. Speilman and Teng's algorithm (the ST-solver)
iteratively produces a sequence of approximate solutions which converge to the 
actual solution of the system $\mat{A} \vect{x} = \vect{b}$. The performance 
of such an iterative system is measured in terms of the time taken to reduce 
an appropriately defined approximation error by a constant factor. The time 
complexity of the ST-solver was reported to be at least $O(m \log^{15} n)$~\cite{KMP11}.  
Koutis, Miller and Peng~\cite{KMP10,KMP11} developed a simpler and faster algorithm 
for finding $\epsilon$-approximate solutions to SDD systems in time 
$\tilde{O}(m \log n \log (1/\epsilon) )$, where the $\tilde{O}$ notation hides 
a factor that is at most $(\log \log n)^2$. A highly readable account 
of SDD systems is the monograph by Vishnoi~\cite{Vis13}. We summarize the 
main result that we use as a black-box.  
\begin{proposition} \label{prop:SDD_systems} {\textrm{\cite{KMP11,Vis13}}}
	Given a system of linear equations $\mat{A} \vect{x} = \vect{b}$, where $\mat{A}$
	is an SDD matrix, there exists an algorithm to compute $\tilde{\vect{x}}$  
	such that:
		\[
			\norm{\tilde{\vect{x}} - \vect{x}}_{\mat{A}} \leq \epsilon \norm{\vect{x}}_{\mat{A}}, 
		\]
	where $\norm{\vect{y}}_{\mat{A}} := \sqrt{\trans{\vect{y}} \mat{A} \vect{y}}$. The algorithm runs in 
	time $\tilde{O}(m \cdot \log n \cdot \log (1 / \epsilon) )$ time, where $m$ is the number of non-zero 
	entries in $\mat{A}$. The $\tilde{O}$ notation hides a factor of at most $(\log \log n)^2$.
\end{proposition} 

%Given an $n \times n$ matrix~$\mat{A}$ and $\vect{b} \in \R^{n}$, consider the 
%system of linear equations $\mat{A} \vect{x} = \vect{b}$, with variables
%$\vect{x} = \trans{(x_1, \ldots, x_n)}$. Such a system has a solution if and only if
%$\vect{b}$ is in the image of matrix~$\mat{A}$. If $\mat{A}$ is invertible, then 
%the system has a solution for all $\vect{b} \in \R^n$. However, if $\vect{b}$ 
%is in the image of $\mat{A}$, then the inverse of $\mat{A}$ is well-defined 
%and is denoted by $\pseudo{\mat{A}}$. This is called the \emph{pseudo-inverse}
%of $\mat{D}$. 
%\begin{proposition} \label{prop:Laplacian_systems} {\textrm{\cite{ST08,Vis13}}}
%	There is an algorithm which takes a graph Laplacian $\mat{L}$, a vector 
%	$\vect{b}$, and an error parameter~$\epsilon > 0$, and returns $\vect{x}$
%	such that:
%		\[
%			\norm{\vect{x} - \pseudo{\mat{L}} \vect{b}}_{\mat{L}} \leq \epsilon \norm{\pseudo{\mat{L}} \vect{b}}_{\mat{L}}, 
%		\]
%	where $\norm{\vect{y}}_{\mat{L}} := \sqrt{\trans{\vect{y}} \mat{L} \vect{y}}$. The algorithm runs in 
%	time $O(m \cdot \log n \cdot \log 1 / \epsilon)$ time, where $m$ is the number of non-zero 
%	entries in $\mat{L}$.
%\end{proposition} 
%This result can be generalized to linear systems $\mat{A} \vect{x} = \vect{b}$, where 
%$\vect{b}$ is a symmetric (weakly) diagonally dominant matrix.

We can use Proposition~\ref{prop:SDD_systems} to upper-bound the time taken to 
calculate $\mat{N} \mat{R}$, where $\mat{N}$ is the fundamental matrix of the absorbing
Markov chain and $\mat{R}$ is as in equation~(\ref{eqn:canonical_form_P}).
\begin{lemma}\label{lemma:computing_NR}
Given a graph~$G$, let $\mat{P}$ be the $n \times n$ transition matrix in canonical form 
(see equation~(\ref{eqn:canonical_form_P})) defined by equations~(\ref{eqn:defining_prob_nonseed}) 
and~(\ref{eqn:defining_prob_seed}). Then one can compute 
$\sum_{r = 0}^{\infty} \mat{Q}^r \cdot \mat{R}$ in $O(s \cdot m \cdot \log n)$ time, 
where $s$ is the number of seed nodes and $m$ is the number of edges in the graph~$G$.
\end{lemma}  
\begin{proof}
Recall that we ordered the nodes of $G$ as $\{u_1, \ldots, u_{n - s}, x_1, \ldots, x_s\}$, 
where $u_1, \ldots, u_{n - s}$ denote the non-seed nodes and $x_1, \ldots, x_s$ denote 
seed nodes. Define $G_1 := G[u_1, \ldots, u_{n - s}]$, the subgraph induced by the non-seed nodes 
of~$G$. Let $\mat{A}_1$ denote the adjacency matrix of the graph $G_1$; let 
$\mat{D}_1$ denote the $(n - s) \times (n - s)$ diagonal matrix satisfying 
$\mat{D}_1(u_i, u_i) = \deg_{G}(u_i)$ for all $1 \leq i \leq n - s$.  That is, the 
entries of $\mat{D}_1$ are not the degrees of the vertices in the induced subgraph~$G_1$ 
but in the graph~$G$. We can then express 
$\mat{I} - \mat{Q}$ as 
\[
	\mat{I}  - \mat{Q} = \inv{\mat{D}_1} (\mat{D}_1 - \mat{A}_1).
\]   
Note that $\mat{D}_1 - \mat{A}_1$ is a symmetric and diagonally dominant matrix. 
Let us suppose that $\mat{X}$ is an $(n - s) \times s$ matrix such that 
\[
	\mat{X} = (\mat{I} - \mat{Q})^{-1} \cdot \mat{R}.
\]
Then $(\mat{I} - \mat{Q}) \mat{X} = \mat{R}$, which may be rewritten as
$(\mat{D}_1 - \mat{A}_1) \mat{X} = \mat{D}_1 \cdot \mat{R}$. The latter 
equation may be written as a set of linear equation systems:
\begin{equation}\label{eqn:laplacian_linear_eqn}
	(\mat{D}_1 - \mat{A}_1) \cdot \vect{x}_i = \mat{D}_1 \cdot \vect{r}_i  \quad (\mbox{for } 1 \leq i \leq s),
\end{equation} 
where $\vect{x}_i$ and $\vect{r}_i$ are the $i\th$ columns of $\mat{X}$ and $\mat{R}$, respectively. 
By Proposition~\ref{prop:SDD_systems}, the time taken to solve each of these systems 
is $O(m \log n)$. Together, they can be solved in time $O(s \cdot m \cdot \log n)$, which
is what was claimed.  

\end{proof} 
