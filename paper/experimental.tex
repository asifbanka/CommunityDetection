Our experimental setup can be roughly divided into five parts (see Figure~\ref{fig:pipeline}) but the 
respective parts differ slightly depending on the case whether we test overlapping or non-overlapping 
communities. First, we use the benchmark graph generator developed by Lacichinetti and Fortunato 
(LFR)~\cite{LFR08, LF09} which outputs graphs where the community information of each node 
is known. Then from each community in our input graph, we pick a fixed number of seed nodes, 
calculate their affinities and feed it to our algorithm. Once the algorithm outputs the 
affinities, we classify the nodes into communities and finally compare the output 
with the ground truth using normalized mutual information (NMI) as a metric~\cite{DDDA05}.


\paragraph{LFR.}
The LFR benchmark (designed by Lancichinetti, Fortunato and Radicci~\cite{LFR08}) 
generates random graphs with community structure that obey a power law 
distribution in both the node degrees and community sizes. The authors designed it 
with the intention to establish a standard benchmark suite for community detection 
algorithms. Using this benchmark they did a comparative analysis of several well-known algorithms
for community detection~\cite{LF09}. To the best of our knowledge, this study seems to be the 
only one where standardized tests were carried out on such a range of community detection algorithms. 
As such, we chose this benchmark for our experiments and set the parameters in the same fashion. 

In what follows, we describe tests for non-overlapping and overlapping communities separately, since 
there are several small differences in out setup for these two cases. 

\subsection{Non-overlapping communities}
The networks we test have either 1000 nodes or 5000 nodes. The average node degree
was set at 20 and the maximum node degree set at 50. The parameter controlling the 
distribution of node degrees was set at~2 and that for the community size distribution was 
set at~1. Moreover, we distinguished between big and small communities: small communities have 
10--50 nodes and large communities have 20--100 nodes. An important parameter 
for the LFR benchmark is the mixing parameter which is the fraction of neighbors 
of a node that do not belong to any community that the node belongs in, averaged over all nodes.
For each of the four combinations of network and community size, we generated graphs with the 
above parameters and with varying mixing parameters. For each of these graphs, we tested the 
community information output by our algorithm and compared it against the ground truth 
using the normalized mutual information as a metric. The plots in the next section 
show how the performance varies as the mixing parameter was changed. Each data point in 
these plots is the average over 100 iterations using the same parameters. 

\paragraph{Seed node generation.} 
To use our algorithm, we expect that users pick seed nodes from 
every community that they wish to identify in the network. One of our assumptions is that
the user knows the more important members of each community. To replicate 
this phenomenon in our experiments, we picked out seed nodes from each community 
with a probability that is proportional to the degree of the node. That is, nodes
with a higher degree were picked in preference to those with a lower degree reflecting the 
fact that ``importance'' in a social network often varies in proportion to the number of 
connections a person has. We note that the actual manner of picking seed nodes did not 
affect the results too much. If we picked seed nodes uniformly at random from each community, 
our results are marginally worse. 

In our experiments, we first selected four values for the percentage of seed nodes 
per community: 5, 10, 15, and 20$\%$. While this gave us decent results, we modified our 
approach slightly so that the algorithm can work with a much smaller set of seed nodes. 
The modified algorithm starts out with an initial set of seed nodes and identifies 
communities but, in addition, also identifies those non-seed nodes that have the 
greatest affinity to their respective communities. These non-seed nodes are then promoted 
to the seed node set in the next round. This process is then iterated so that at the end of each 
round the algorithm collects a larger set of seed nodes per community. We tested this approach with 
2, 4, 6, 8, and 10$\%$ seed nodes and fixed the number of iterations to 10. 

\paragraph{Classification into communities.}
The algorithm outputs the affinity vectors of all non-seed nodes. The procedure 
used to classify nodes into communities consists of identifying for each non-seed 
node the community for which it has the highest affinity, with ties broken arbitrarily. 
For each round of the modified iterated algorithm, we simply identify all those nodes 
whose highest affinity exceeds a given threshold. \texttt{Correct???} These nodes are then 
promoted into the seed node set for the next round. The number of rounds can be specified by 
the user and in the final round, we simply classify the remaining non-seed nodes into the community
for which they have maximum affinity. \texttt{Looks like this can be stated more simply.}

\subsection{Overlapping Communities.}
\texttt{Please verify whether the parameter values mentioned are correct!!!!}
The LFR benchmark suite can generate networks with an overlapping community structure. 
In addition to the parameters mentioned for the non-overlapping case, there is an additional 
parameter that controls what fraction of nodes of the network are in multiple communities. 
As in the non-overlapping case, we generated graphs with 1000 and 5000 nodes with the average
node degree set at 20 and maximum node degree set at 50. We generated graphs with two types 
of community sizes: small communities with 10--50 nodes and large communities with 20--100 nodes.
Moreover, as in~\cite{LF09}, we chose two values for the maxing factor: $0.1$ and $0.3$. 
The plots in this case compared the algorithm output as against the ground truth (measure by 
the NMI) for varying fractions of overlapping nodes. 

\paragraph{Seed Generation.}
As in the case for non-overlapping communities, we experimented with a non-iterative 
and an iterative version of our approach. For the non-iterative version, the percentage 
of seed nodes that we picked were 5, 10, 15 and 20$\%$ per community, with the probability
of picking a node being proportional to its degree. For the iterative version, we used 
2, 4, 6, 8 and 10$\%$ seed nodes per community. 

\paragraph{Classification into communities.} For the overlapping case, we simply 
cannot use a naive strategy of classifying a node to the community for which it has 
the highest affinity. A node can potentially belong to multiple communities and yet 
the affinities to these communities, as output by our algorithm, can vary quite a lot. 
This variation occurs partly due to the manner in which seed nodes are chosen. A node $u$ might 
belong to two communities $A$ and $B$, but the seed nodes of $A$ might lie closer to $u$ than the 
seed nodes of $B$. This would skew the affinity of $u$ in $A$'s favor. \texttt{What are the other reasons 
as to why affinities vary??}

We could have chosen a threshold value and placed a node to all those communities for which 
it has an affinity that exceeds that threshold. We suspect that there is no one threshold 
which we can use and this would necessitate choosing different ``magic numbers'' for every network 
that we experiment on. The affinity vector for a node calculated by the 
algorithm might assign varying affinities for each of the communities that it belongs to, but we expect 
that the algorithm assigns very low affinities to the communities that the node does \emph{not} belong to. 
This suggests the following strategy. Sort the affinities of a node in non-increasing order and let this 
sequence be $a_1, \ldots, a_k$. Calculate the differences $\Delta_{1} := a_1 - a_2, \ldots, 
\Delta_{k-1} := a_{k - 1} - a_k$ and let $i$ be the smallest index for which the difference $\Delta_i$ is 
a maximum. We then associate the node with the communities to which it the affinities $a_1, \ldots, a_i$. 
The intuition is that, while the node can have a varying affinity to the communities it belongs to, 
there is a likely to be a sharp decrease in affinities for the communities that the node does 
not belong in. This is what is captured by the computing the difference in affinities.

\paragraph{Normalized Mutual Information.}
