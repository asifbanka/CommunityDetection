Our experimental setup can be roughly divided into five parts (see Figure~\ref{fig:pipeline}) but the 
respective parts differ slightly depending on whether we test overlapping or non-overlapping 
communities. First, we use the benchmark graph generator developed by Lacichinetti and Fortunato 
(LFR)~\cite{LFR08, LF09}, which outputs graphs where the community information of each node 
is known. Then from each community in our input graph, we pick a fixed number of seed nodes, 
calculate their affinities and feed it to our algorithm. Once the algorithm outputs the 
affinities, we classify the nodes into communities and finally compare the output 
with the ground truth using normalized mutual information (NMI) as a metric~\cite{DDDA05}.

\texttt{General question: should we use present tense or past to describe our setup?}

\paragraph{LFR.}
The LFR benchmark (designed by Lancichinetti, Fortunato and Radicci~\cite{LFR08}) 
generates random graphs with community structure that obey a power law 
distribution in both the node degrees and community sizes. The authors designed it 
with the intention to establish a standard benchmark suite for community detection 
algorithms. Using this benchmark they did a comparative analysis of several well-known algorithms
for community detection~\cite{LF09}. To the best of our knowledge, this study seems to be the 
only one where standardized tests were carried out on such a range of community detection algorithms. 
\texttt{jan: first google result for "comparision overlapping community detection":
http://arxiv.org/abs/1110.5813 However, they also use LFR.}
As such, we chose this benchmark for our experiments and set the parameters in the same fashion. 

In what follows, we describe tests for non-overlapping and overlapping communities separately, since 
there are several small differences in out setup for these two cases. 

\subsection{Non-overlapping communities}
The networks we test have either 1000 nodes or 5000 nodes. The average node degree
was set at 20 and the maximum node degree set at 50. The parameter controlling the 
distribution of node degrees was set at~2 and that for the community size distribution was 
set at~1. Moreover, we distinguished between big and small communities: small communities have 
10--50 nodes and large communities have 20--100 nodes. An important parameter 
for the LFR benchmark is the mixing parameter which is the fraction of neighbors 
of a node that do not belong to any community that the node belongs to, averaged over all nodes.
For each of the four combinations of network and community size, we generated graphs with the 
above parameters and with varying mixing parameters. For each of these graphs, we tested the 
community information output by our algorithm and compared it against the ground truth 
using the normalized mutual information as a metric. The plots in the next section 
show how the performance varies as the mixing parameter was changed. Each data point in 
these plots is the average over 100 iterations using the same parameters. 

\paragraph{Seed node generation.} 
To use our algorithm, we expect that users pick seed nodes from 
every community that they wish to identify in the network. 
We simulate this by picking a fixed fraction of nodes from each community as seed nodes.
One of our assumptions is that the user knows the more important members of each community. 
To replicate this phenomenon in our experiments, we picked a node as seed node
with a probability that is proportional to the degree of the node.
That is, nodes with a higher degree were picked in preference to those with a lower degree.
For those nodes which were picked as seed nodes we set the affinity to a community to 1 iff
the node belongs to this community, otherwise 0.
%We note that the actual manner of picking seed nodes did not 
%affect the results too much. 
%If we picked seed nodes uniformly at random from each community, our results are marginally worse.

\paragraph{Classification into communities.}
Next, the algorithm is run on the network together with the affinity information of the seed nodes.
Afterwards, we need to assign the nodes into communities, 
based on the affinity vectors the algorithm assigned to each node.
When detecting non-overlapping communities, we know that each vetex is in exactly one community,
thus we assign each node to the community to which it has the highest affinity.

\paragraph{Iteration.}
We extended the algorithm to iteratively improve the goodness of the community detection.
The idea is, that after running the algorithm once, there are
certain nodes, for which we are quite certain which community they belong to.
We add these nodes to the seed node set of the respective community
and perform another round of community detection.
To be precise, in the $k\th$ round, let $C^k_i$ be the set of nodes which were classified to be in community $i$ and $S^k_i$ be the seed nodes of community $i$.
While $| S^{k+1}_i | \le f \cdot | S^{k}_i |$, we add those nodes from $C^k_i$ to $S^{k+1}_i$ which have the hightest affinity to this community.
The factor $f$ declares be how much the set of seed nodes is allowed to grow in each iteration. 
Chosing $f$ to be 1.1 gives good results.
Repeating this procedure a couple times significantly improves the community detection.


%In our experiments, we first selected four values for the percentage of seed nodes 
%per community: 5, 10, 15, and 20$\%$. While this gave us decent results, we modified our 
%approach slightly so that the algorithm can work with a much smaller set of seed nodes. 
%The modified algorithm starts out with an initial set of seed nodes and identifies 
%communities but, in addition, also identifies those non-seed nodes that have the 
%greatest affinity to their respective communities. These non-seed nodes are then promoted 
%to the seed node set in the next round. This process is then iterated so that at the end of each 
%round the algorithm collects a larger set of seed nodes per community. We tested this approach with 
%2, 4, 6, 8, and 10$\%$ seed nodes and fixed the number of iterations to 10. 

%\paragraph{Classification into communities.}
%The algorithm outputs the affinity vectors of all non-seed nodes. The procedure 
%used to classify nodes into communities consists of identifying for each non-seed 
%node the community for which it has the highest affinity, with ties broken arbitrarily. 
%For each round of the modified iterated algorithm, we simply identify all those nodes 
%whose highest affinity exceeds a given threshold. \texttt{Correct???} These nodes are then 
%promoted into the seed node set for the next round. The number of rounds can be specified by 
%the user and in the final round, we simply classify the remaining non-seed nodes into the community
%for which they have maximum affinity. \texttt{Looks like this can be stated more simply.}

\subsection{Overlapping Communities.}
\texttt{Please verify whether the parameter values mentioned are correct!!!!}
The LFR benchmark suite can generate networks with an overlapping community structure. 
In addition to the parameters mentioned for the non-overlapping case, there is an additional 
parameter that controls what fraction of nodes of the network are in multiple communities. 
As in the non-overlapping case, we generated graphs with 1000 and 5000 nodes with the average
node degree set at 20 and maximum node degree set at 50. We generated graphs with two types 
of community sizes: small communities with 10--50 nodes and large communities with 20--100 nodes.
Moreover, as in~\cite{LF09}, we chose two values for the maxing factor: $0.1$ and $0.3$. 
The plots in this case compared the algorithm output as against the ground truth (measure by 
the NMI) for varying fractions of overlapping nodes. 

\paragraph{Seed Generation.}
As in the case for non-overlapping communities, we experimented with a non-iterative 
and an iterative version of our approach. For the non-iterative version, the percentage 
of seed nodes that we picked were 5, 10, 15 and 20$\%$ per community, with the probability
of picking a node being proportional to its degree. For the iterative version, we used 
2, 4, 6, 8 and 10$\%$ seed nodes per community. 

\paragraph{Classification into communities.} For the overlapping case, we simply 
cannot use a naive strategy of classifying a node to the community for which it has 
the highest affinity. A node can potentially belong to multiple communities and yet 
the affinities to these communities, as output by our algorithm, can vary quite a lot. 
This variation occurs partly due to the manner in which seed nodes are chosen. A node $u$ might 
belong to two communities $A$ and $B$, but the seed nodes of $A$ might lie closer to $u$ than the 
seed nodes of $B$. This would skew the affinity of $u$ in $A$'s favor. \texttt{What are the other reasons 
as to why affinities vary??}

We could have chosen a threshold value and placed a node to all those communities for which 
it has an affinity that exceeds that threshold. We suspect that there is no one threshold 
which we can use and this would necessitate choosing different ``magic numbers'' for every network 
that we experiment on. The affinity vector for a node calculated by the 
algorithm might assign varying affinities for each of the communities that it belongs to, but we expect 
that the algorithm assigns very low affinities to the communities that the node does \emph{not} belong to. 
This suggests the following strategy. Sort the affinities of a node in non-increasing order and let this 
sequence be $a_1, \ldots, a_k$. Calculate the differences $\Delta_{1} := a_1 - a_2, \ldots, 
\Delta_{k-1} := a_{k - 1} - a_k$; let $\Delta_{\mathrm{max}}$ denote the maximum difference 
and let $i$ be the smallest index for which $\Delta_i = \Delta_{\mathrm{max}}$. We then associate 
the node with the communities to which it has the affinities $a_1, \ldots, a_i$. 
The intuition is that, while the node can have a varying affinity to the communities it belongs to, 
there is a likely to be a sharp decrease in affinities for the communities that the node does 
not belong in. This is what is captured by the computing the difference in affinities and then finding 
out the first large decrease in affinities.

\paragraph{Normalized Mutual Information.}
This is an information-theoretic measure that allows us the 
compare the ``distance'' between two partitions of a finite set. Let $V$ be a finite set 
with $n$ elements and let $\mathcal{A}$ and $\mathcal{B}$ be two partitions of $V$. The probability that an 
element chosen uniformly at random belongs to a partite set $A \in \mathcal{A}$ is $n_A/n$, where $n_A$ 
is the number of elements in $A$. The Shannon entropy of the partition $\mathcal{A}$ 
is defined as:
\begin{equation}\label{eqn:shannon_entropy}
H(\mathcal{A}) = - \sum_{A \in \mathcal{A}} \frac{n_A}{n} \log_2 \frac{n_A}{n}.
\end{equation}

The mutual information of two random variables is a measure of their mutual dependence. For random 
variables $X$ and $Y$ with probability mass functions $p(x)$ and $p(y)$, respectively, and 
with a joint probability mass function $p(x, y)$, the \emph{mutual information $I(X, Y)$} 
is defined as:
\begin{equation}\label{eqn:mutual_information_rv}
I(X, Y) = \sum_{x \Omega(X)} \sum_{y \in \Omega(Y)} p(x, y) \log \frac{p(x, y)}{p(x) p(y)},
\end{equation}
where $\Omega(X)$ is the event space of the random variable $X$.
The mutual information of two partitions $\mathcal{A}$ and $\mathcal{B}$ 
of the node set of a graph is calculated by using the so-called ``confusion matrix'' 
$\mat{N}$ whose rows correspond to ``real'' communities and whose columns correspond 
to ``found'' communities. The entry $\mat{N}(A, B)$ is the number of nodes of community 
$A$ in partition $\mathcal{A}$ that are classified into community $B$ in partition $\mathcal{B}$. 
The mutual information is defined as:
\begin{equation}\label{eqn:mutual_information_graphs}
I(\mathcal{A}, \mathcal{B}) = 
	\sum_{A \in \mathcal{A}} \sum_{B \in \mathcal{B}} \frac{n_{A, B}}{n} 
		\log \frac{n_{A, B} / n}{ (n_A / n) \cdot (n_B / n) }.  
\end{equation}

Danon \etal~\cite{DDDA05} suggested to use a normalized variant of this measure. The 
normalized mutual information $I_N(\mathcal{A}, \mathcal{B})$ between partitions 
$\mathcal{A}$ and $\mathcal{B}$ is defined as:
\begin{equation} \label{eqn:normalized_mutual_information}
I_N(\mathcal{A}, \mathcal{B}) =  \frac{2 I(\mathcal{A}, \mathcal{B})}{H(\mathcal{A}) + H(\mathcal{B})}.
\end{equation}
The normalized mutual information takes the value~1 when both partitions are identical. If both partitions 
are independent of each other, then $I_N(\mathcal{A}, \mathcal{B}) = 0$. 

The classical notion of normalized mutual information measures the distance  between 
two \emph{partitions} and hence cannot be used for overlapping community detection. 
Lancichinetti, Fortunato, and Kert\'{e}sz~\cite{LFK09} proposed a definition of the measure for 
evaluating the similarity of covers, where a \emph{cover} of the node set of a graph 
is a collection of node subsets such that every node of the graph is in at least one set. 
Their definition of normalized mutual information is:
\begin{equation} \label{eqn:nmi_LFK}
\NMI_{\mathrm{LFK}} := 1 - \frac{1}{2} 
		\left ( \frac{H(\mathcal{A} | \mathcal{B})}{H(\mathcal{A})} + \frac{H(\mathcal{B}
				| \mathcal{A})}{H(\mathcal{B})}\right ).
\end{equation}
This definition is not exactly an extension of normalized mutual information in that the values
obtained by evaluating it on two partitions is different from what is given by normalized mutual 
information evaluated on the same pair of partitions.

\texttt{Extension by McDaid et al. Should point out the criticism of using the LFK NMI measure 
to evaluate overlapping community structure.}
