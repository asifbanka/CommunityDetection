Our experimental setup can be roughly divided into five parts (see Figure~\ref{fig:pipeline}) but the 
respective parts differ slightly depending on the case whether we test overlapping or non-overlapping 
communities. First, we use the benchmark graph generator developed by Lacichinetti and Fortunato 
(LFR)~\cite{LFR08, LF09} which outputs graphs where the community information of each node 
is known. Then from each community in our input graph, we pick a fixed number of seed nodes, 
calculate their affinitites and feed it to our algorithm. Once the algorithm outputs the 
affinities, we classify the nodes into communitites and finally compare the output 
with the ground truth using normalized mutual information (NMI) as a metric~\cite{DDDA05}.


\paragraph{LFR.}
The LFR benchmark (designed by Lancichinetti, Fortunato and Radicci~\cite{LFR08}) 
generates random graphs with community structure that obey a power law 
distribution in both the node degrees and community sizes. The authors designed it 
with the intention to establish a standard benchmark suite for community detection 
algorithms. Using this benchmark they did a comparative analysis of several well-known algorithms
for community detection~\cite{LF09}. To the best of our knowledge, this study seems to be the 
only one where standardized tests were carried out on such a range of community detection algorithms. 
As such, we chose this benchmark for our experiments and set the parameters in the same fashion. 

In what follows, we describe tests for non-overlapping and overlapping communities separately, since 
there are several small differences in out setup for these two cases. 

\subsection{Non-overlapping communities}
The networks we test have either 1000 nodes or 5000 nodes. The average node degree
was set at 20 and the maximum node degree set at 50. The parameter controlling the 
distribution of node degrees was set at~2 and that for the community size distribution was 
set at~1. Moreover, we distinguished between big and small communities: small communities have 
10--50 nodes and large communities have 20--100 nodes. An important parameter 
for the LFR benchmark is the mixing parameter which is the fraction of neighbors 
of a node that do not belong to any community that the node belongs in, averaged over all nodes.
For each of the four combinations of network and community size, we generated graphs with the 
above parameters and with varying mixing parameters. For each of these graphs, we tested the 
community information output by our algorithm and compared it against the ground truth 
using the normalized mutual information as a metric. The plots in the next section 
show how the performance varies as the mixing parameter was changed. Each data point in 
these plots is the average over 100 iterations using the same parameters. 

\paragraph{Seed node generation.} 
To use our algorithm, we expect that users pick seed nodes from 
every community that they wish to identify in the network. One of our assumptions is that
the user knows the more important members of each community. To replicate 
this phenomenon in our experiments, we picked out seed nodes from each community 
with a probability that is proportional to the degree of the node. That is, nodes
with a higher degree were picked in preference to those with a lower degree reflecting the 
fact that ``importance'' in a social network often varies in proportion to the number of 
connections a person has. We note that the actual manner of picking seed nodes did not 
affect the results too much. If we picked seed nodes uniformly at random from each community, 
our results are marginally worse. 

In our experiments, we first selected four values for the percentage of seed nodes 
per community: 5, 10, 15, and 20$\%$. While this gave us decent results, we modified our 
approach slightly so that the algorithm can work with a much smaller set of seed nodes. 
The modified algorithm starts out with an initial set of seed nodes and identifies 
communities but, in addition, also identifies those non-seed nodes that have the 
greatest affinity to their respective communitites. These non-seed nodes are then promoted 
to the seed node set in the next round. This process is then iterated so that at the end of each 
round the algorithm collects a larger set of seed nodes per community. We tested this approach with 
2, 4, 6, 8, and 10$\%$ seed nodes and fixed the number of iterations to 10. 

\paragraph{Classification into communities.}
The algorithm outputs the affinity vectors of all non-seed nodes. The procedure 
used to classify nodes into communitites consists of identifing for each non-seed 
node the community for which it has the highest affinity, with ties broken arbitrarily. 
For each round of the modified iterated algorithm, we simply identify all those nodes 
whose highest affinity exceeds a given threshold. \texttt{Correct???} These nodes are then 
promoted into the seed node set for the next round. The number of rounds can be specified by 
the user and in the final round, we simply classify the remaining non-seed nodes into the community
for which they have maximum affinity. \texttt{Looks like this can be stated more simply.}

\subsection{Overlapping Communities.}
\texttt{Please verify whether the parameter values mentioned are correct!!!!}
The LFR benchmark suite can generate networks with an overlapping community structure. 
In addition to the parameters mentioned for the non-overlapping case, there is an additional 
parameter that controls what fraction of nodes of the network are in multiple communities. 
As in the non-overlapping case, we generated graphs with 1000 and 5000 nodes with the average
node degree set at 20 and maximum node degree set at 50. We generated graphs with two types 
of community sizes: small communitites with 10--50 nodes and large communities with 20--100 nodes.
Moreover, as in~\cite{LF09}, we chose two values for the maxing factor: $0.1$ and $0.3$. 
The plots in this case compared the algorithm output as against the ground truth (measure by 
the NMI) for varying fractions of overlapping nodes. 

\paragraph{Seed Generation.}
As in the case for non-overlapping communities, we experimented with a non-iterative 
and an iterative version of our approach. For the non-iterative version, the percentage 
of seed nodes that we picked were 5, 10, 15 and 20$\%$ per community, with the probability
of picking a node being proportional to its degree. For the iterative version, we used 
2, 4, 6, 8 and 10$\%$ seed nodes per community. 

\paragraph{Classification into communitites.} For the overlapping case, we simply 
cannot use a naive strategy of classifying a node to the community for which it has 
the highest affinity. A node can potentially belong to multiple communities and yet 
the affinitites to these communities, as output by our algorithm, can vary quite a lot. 
This variation occurs partly due to the manner in which seed nodes are chosen. A node $u$ might 
belong to two communities $A$ and $B$, but the seed nodes of $A$ might lie closer to $u$ than the 
seed nodes of $B$. This would skew the affinity of $u$ in $A$'s favor. \texttt{What are the other reasons 
as to why affinities vary??}


\paragraph{Random Walk.}
The coded algorithm itself is a realization of the theoretical formulations we 
established in Chapter~\ref{sec:algorithm}. Since initial test runs required a high amount
of seed nodes $S$ in order to get satisfying results, we further enhanced our algorithm by implementing 
an iterative computation method. After one run of the regular algorithm we try to increase the amount of 
seed nodes per community. We do so by checking the highest affinity value $a < 1$ per vertex and include 
it to a set of potential new seed nodes for the respective community. After we established at most 
$d * \left| S \right|$ new seed nodes per community, we rerun the algorithm. The parameter $d$ sets 
the desired enlargement of $S$ and was set to $0.1$ in our experiments. We repeat this process for 
$10$ iterations.

\paragraph{Classification.}
The algorithm outputs affinity values for every vertex community combination. 
these values range between zero and one and are the sole factor whether we 
assign a vertex to a community or not. At this point the strategy for community classification is 
different depending on whether we deal with overlapping communities or not. In the latter case we 
know that a vertex is assigned to exactly one community. thus, we assign the community for which 
the respective vertex has the highest respective affinity value. 

In the overlapping case we apply a slightly more sophisticated strategy, since a vertex is maybe 
assigned to not just one but potentially all communities. First, we assume that there are one 
or more ``high'' affinity values which would correspond to the 
case that a vertex is in favor to be assigned to a community. On the other hand, there are one or 
more ``low'' values in the other case. However, we can not make any more qualified statements 
about the actual values of the affinities, since these numbers differ greatly depending on the 
structure of the graph and on the amount of communities a vertex belongs to. Therefore, we can 
only assume that there is some difference in high and low values. For this reason, we first 
sort the affinities in descending order. then we compare all subsequent pairs by computing 
the difference. Then we define the point where we found the largest difference as our border 
between low and high affinity values. Any associated community left of this border is 
assigned to the respective vertex, whereas any affinity value on the right hand side is considered 
as a low value and thus the respective community is not assigned.

\paragraph{NMI.}
After we have assigned the communities to our vertices we now want to measure 
the quality of our predictions. As Lacichinetti and Fortunato 
suggest~\cite{LF09} we determine the NMI values of the predicted community 
assignment and the ground truth. The NMI determines how similar the 
information in bits is. \texttt{This section could have a little more text, as to what NMI is}
