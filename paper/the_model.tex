A \emph{social network} consists of a set of social actors and a set of ties 
between them. A social network is modeled as a graph which may be directed 
or undirected. In this paper, we deal with social networks that are modeled as undirected 
graphs. In the context of community detection in social networks, we make 
the following assumptions. 

Our first assumption is that we know what the network at hand represents. That is, 
we have a sense of context about the network. The network could represent 
friendships as in the Facebook network; co-authorships as in the DBLP network; 
it could be a network of professionals such as LinkedIn, or a network of movie 
lovers such as IMDB. Secondly, we assume that we know what is it that constitutes 
a community within the network. This is crucial because, for one, we do not 
formally define what a community is. We take it as being given as part of the 
input specification. While this may appear as an artifice, in many real-life situations 
where we are required to find communities, we do in fact know what 
it is that we are searching for. For example, we might want to find the set of 
people with a given political leaning, or a set of people who love a particular 
genre of movie, or a set of people with a specific skill-set and experience. 
In each of these cases, we have a sense of what it is that is required to be found. 

In broad brush-strokes, this is how our algorithm works.  It requires that we know
some members from each community that we are aiming to discover. We call these members 
\emph{seed nodes}. A seed node can belong to several communitites and our algorithm 
actually finds out overlapping communities in the network. The algorithm uses the 
partial community information and propagates it to the other nodes of the network 
by simulating a random walk from non-seed nodes to the set of seed nodes. 

Suppose that $x_1, \ldots, x_s$ are the seed nodes in the network and that a random walk starting at 
a non-seed node~$u$ reaches these nodes with probabilities $p_1, \ldots, p_s$. If out 
of these~$s$ seed nodes, $x_{i_1}, \ldots, x_{i_r}$ belong to a community~$C$, then 
the algorithm assigns a probability of $\sum_{j = 1}^r p_{i_j}$ for the event 
that~$u$ belongs to~$C$. For each community, we can now assign a probability for 
the event that~$u$ belongs to it. The communities that the algorithm 
assigns~$u$ are those for which the probabilities exceed a certain threshold. 

The random walk can be represented by a transition matrix and the walk itself can be simulated 
by multiplying this matrix with itself repeatedly. This, however, takes $O(n^3)$
time, where~$n$ is the number of nodes in the network. One of the contributions of 
this paper is to show how this can be reduced to solving a set of (symmetric, diagonally dominant) 
systems of linear equations (one set per community), which can be done in $O(m \log n)$ time, 
where~$m$ is the number of edges in the graph. The fact that such systems can be solved in 
almost linear time was due to work that was spearheaded by Speilman and 
Teng~\cite{ST04,EEST05,ST08,KMP10,KMP11,Vis13}. We assume that our networks are 
sparse in the sense that $m = O(n)$, so that the running time of our algorithm can  
be bounded by $O(n \log n)$.    
        
\subsection{Absorbing Markov Chains and Random Walks}
We now provide a formal description of our model. We assume that our network 
is a simple undirected graph $G = (V,E)$ with~$n$ nodes and~$m$ edges, where $m = O(n)$.
We also know that there are~$k$ communities which may overlap in an arbitrary fashion.
In practical situations, we have~$k \ll n$. 
Moreover, we have some partial information about each community in that we know
$\log n$ members of each community. Call such members of the network \emph{seed nodes} 
and the remaining nodes \emph{non-seed nodes}. Together, we know the community information 
of $k \cdot \log n$ seed nodes. The community information of a node~$u$ is represented 
by a $1 \times k$ vector called the \emph{affinity vector} of~$u$, denoted 
by 
\[
	\bvect (u) = \trans{\left ( \alpha (u, 1), \ldots, \alpha (u, k) \right )}.
\] 
The entry $\alpha (u, i)$ of the affinity vector represents the probability that 
node~$u$ belongs to community~$i$.  We call this the \emph{affinity of node~$u$} for 
community~$i$. We point out that $\sum_{i = 1}^k \alpha (u, i)$ 
need not be~$1$. An example of this situation is when~$u$ belongs to multiple 
communities with probability~$1$. The objective is to find out the belonging 
vectors of all non-seed nodes. 

To model our random walk, we define an $n \times n$ transition matrix $\mat{P}$ 
as follows. We first assume that the nodes of~$G$ are ordered as 
$u_1, \ldots, u_{n - s}, x_{1}, \ldots, x_{s}$, where $u_1, \ldots, u_{n - s}$
represent the non-seed nodes of the network and $x_1, \ldots, x_s$, the seed nodes.
For a non-seed node~$u$:
\begin{equation}\label{eqn:defining_prob_nonseed}
	\mat{P}(u, z) = \left \{ 
							\begin{array}{ll}
								\frac{1}{\deg (u)} & \mbox{ if } \{u, z\} \in E(G) \\
								0			& \mbox{ otherwise.}
							\end{array}
						\right.
\end{equation}
Note that the sum of the entries of row~$u$ is~$1$. 
For a seed node~$x$, 
\begin{equation}\label{eqn:defining_prob_seed}
	\mat{P}(x,z) = 	\left \{ 
						\begin{array}{ll}
							1 & \mbox{if $z = x$} \\
							0 & \mbox{if $z \neq x$.}
						\end{array}
					\right.
\end{equation}

It is usual to write the transition matrix $\mat{P}$ in the following canonical form:
\begin{equation}\label{eqn:canonical_form_P}
	\mat{P} = 	\left [ \begin{array}{ll}
						\mat{Q}  & \mat{R} \\
						 \mat{0}_{s \times (n - s)} & \mat{I}_{s \times s}
						\end{array}
				\right ],
\end{equation}
where~$\mat{Q}$ is the $(n - s) \times (n - s)$ sub-matrix that represents the transition 
from non-seed nodes to non-seed nodes; $\mat{R}$ is the $(n - s) \times s$ sub-matrix 
that represents the transition from non-seed nodes to seed nodes. The $s \times s$ identity 
matrix $\mat{I}$ represents the fact that once a seed node is reached, one cannot transition away 
from it. Here $\mat{0}_{s \times (n - s)}$ represents an $s \times (n - s)$ matrix of zeros. 
Since each row of $\mat{P}$ sums up to~$1$, this matrix is stochastic.

It is well-known that such a stochastic matrix represents, what is known as, an 
absorbing Markov chain (see, for example, Chapter~11 of Grinstead and Snell~\cite{GS98}).  
A Markov chain is called \emph{absorbing} if it satisfies two conditions. 
It must have at least one absorbing state~$i$, where state~$i$ is defined 
to be absorbing if and only if $\mat{P}(i,i) = 1$ and $\mat{P}(i, j) = 0$ 
for all $j \neq i$. Secondly, it must be possible to transition from every state to 
    some absorbing state (perhaps in multiple steps). 

The transition matrix $\mat{P}$ that we defined via equations~(\ref{eqn:defining_prob_nonseed}) 
and~(\ref{eqn:defining_prob_seed}) satisfy these two properties. To see this, note that 
the transition matrix implicitly defines an arc-weighted  directed graph on the nodes 
of the network. Call this directed graph $G_{\mat{P}}$. For non-seed nodes~$u$ and~$v$ that 
are connected by an edge in the network, there exist two arcs $(u, v)$ and $(v, u)$ 
in $G_{\mat{P}}$ with weights $1/\deg (u)$ and $1/ \deg (v)$, respectively.
If $x$ is a seed node with $p$ non-seed neighbors 
$u_1, \ldots, u_p$, then the edges~$\{u_i, x\}$ in~$G$, for $1 \leq i \leq p$, 
are represented by arcs~$(u_i, x)$ (with weight $1 / \deg (u_i)$) in $G_{\mat{P}}$. 
In addition, $x$ has self-loop with weight~$1$. It is worthwhile to note 
that if two seed nodes are adjacent in~$G$, then the corresponding edge does not have a 
directed counterpart in $G_{\mat{P}}$.  

Now from the theory of Markov chains, the state of the system after a $r$-step transition 
is given by the matrix product $\mat{P}^r$. Moreover, $\mat{P}^r (u, v)$ may be interpreted 
as the probability that a random walk starting at node~$u$ will end up at node~$v$ 
after~$r$ steps. Since the underlying network is connected, every non-seed node can reach a seed
node by some path and such a dipath continues to exist in $D_{\mat{P}}$. This shows that $D_{\mat{P}}$
is indeed an absorbing Markov chain. An easy property of such Markov chains is the following:
\begin{equation}\label{exp:rth_product_of_P}
	\mat{P}^r = \left [ \begin{array}{ll}
						\mat{Q}^r  					& \sum_{i = 0}^{r - 1}\mat{Q}^i \cdot \mat{R} \\
						 \mat{0}_{s \times (n - s)} & \mat{I}_{s \times s}
						\end{array}
				\right ].
\end{equation}  
It can be shown that $\lim_{r \to \infty} \mat{Q}^{r} = \mat{0}$ and that 
the series $\sum_{r = 0}^{\infty} \mat{Q}^{r}$ actually converges to 
$(\mat{I} - \mat{Q})^{-1}$. This matrix series is called the \emph{fundamental matrix}
of the absorbing Markov chain and is denoted by $\mat{N}$. 

We summarize some of the properties of an absorbing Markov chain. 
\begin{proposition}\label{prop:limiting_Q}
	Let $\mat{P}$ be the $n \times n$ transition matrix that defines an absorbing Markov chain
	and suppose that $\mat{P}$ is in the canonical form specified by equation~(\ref{eqn:canonical_form_P}). 
	Then
	\begin{enumerate}
		\item $\lim_{r \to \infty} \mat{Q} = \mat{0}_{(n - s) \times (n - s)}$.
		\item $\sum_{r = 0}^{\infty} \mat{Q}^r \cdot \mat{R} = (\mat{I} - \mat{Q})^{-1} \cdot \mat{R}$.
	\end{enumerate} 
\end{proposition}

We wish to determine the matrix $\mat{N} \mat{R}$: the entry $(u, x)$ of this 
matrix is the probability that a random walk starting at~$u$ ends up at the seed 
node~$x$. Once we have determined this matrix, the affinity of $u$ for 
a community~$j$ can be computed as:
\begin{equation}\label{eqn:belonging_vector}
	\alpha (u, j) = \sum_{i = 1}^{s} (\mat{N} \mat{R}) (u, x_i) \cdot \alpha (x_i, j).
\end{equation}
If we compute $\mat{N}$ by first computing the inverse $(\mat{I} - \mat{Q})^{-1}$
and then multiplying the result by $\mat{R}$, we taken time $O(n^3)$. In the 
next subsection, we show how to reduce this problem to that of solving a 
system of linear equations of a special type which takes time $O(m \log n)$, where $m$
is the number of edges. 

\subsection{Symmetric Diagonally Dominant Linear Systems}

An $n \times n$ matrix $\mat{A} = [a_{ij}]$ is \emph{diagonally dominant} if 
\[
	|a_{ii}| \geq \sum_{j \neq i} {|a_{ij}|} \mbox{ for all } i = 1, \ldots, n.
\] 
A matrix is \emph{symmetric diagonally dominant (SDD)} if, in addition to the above, 
it is symmetric. For more information about matrices and matrix computations, 
see the texbooks by Golub and Van Loan~\cite{GvL13} and Horn and Johnson~\cite{HJ13}. 

An example of a symmetric, diagonally dominant matrix is the graph Laplacian. 
Given an unweighted, undirected graph~$G$, the \emph{Laplacian} of $G$ 
is defined to be 
\[
\mat{L}_G = \mat{D}_G - \mat{A}_G,
\] 
where $\mat{A}_G$ is the adjacency matrix of the graph~$G$ and $\mat{D}_G$ 
is the diagonal matrix of vertex degrees. This definition extends 
to weighted graphs. A weighted graph $G = (V, E)$ has an associated weight function 
$w \colon V \times V \to \R$ which satisfies the conditions: 
\begin{inparaenum}[(1)]
	\item $w(u, v) = w(v, u)$;  
	\item $w(u, v) \geq 0$; and, 
	\item if $\{u, v\} \notin E$ then $w(u, v) = 0$. 
\end{inparaenum}
In the context of weighted graphs, the degree~$\deg_G (u)$ of a vertex~$u$ is defined to be 
\[\label{eqn:weighted_degree}
	\deg_G (u) = \sum_{v \in V} w(u, v). 
\] 
The adjacency matrix $\mat{A}_{G}$ is defined as:
\[\label{eqn:weighted_adj_matrix}
	\mat{A}_{G}(u, v) = w(u, v),
\]
and the Laplacian is defined as before as: 
\[\label{eqn:weighted_laplacian}
	\mat{L}_G = \mat{D}_G - \mat{A}_G,
\]
where $\mat{D}_G$ is the diagonal matrix of vertex degrees in the weighted graph~$G$.

A symmetric, diagonally dominant (SDD) system of linear equations is a system of 
equations of the form:
\[
	\mat{A} \cdot \vect{x} = \vect{b},
\]
where $\mat{A}$ is an SDD matrix, $\vect{x} = \trans{(x_1, \ldots, x_n)}$ 
is a vector of unknowns, and $\vect{b} = \trans{(b_1, \ldots, b_n)}$ is a vector of constants. 
There is near-linear time algorithm for solving such a system of linear equations 
and this result is crucial to the analysis of the running time of our algorithm. 

The solution of $n \times n$ system of linear equations takes $O(n^3)$ time 
if one uses Gaussian elimination. \texttt{More stuff here on sparse systems ...}
Speilman and Teng made a seminal contribution in this direction and 
showed that SDD linear systems can be solved in nearly-linear 
time~\cite{ST04,EEST05,ST08}. Speilman and Teng's algorithm (the ST-solver)
iteratively produces a sequence of approximate solutions which converge to the 
actual solution of the system $\mat{A} \vect{x} = \vect{b}$. The performance 
of such an iterative system is measured in terms of the time taken to reduce 
an appropriately defined approximation error by a constant factor. The time 
complexity of the ST-solver was reported to be at least $O(m \log^{15} n)$~\cite{KMP11}.  
Koutis, Miller and Peng~\cite{KMP10,KMP11} developed a simpler and faster algorithm 
for finding $\epsilon$-approximate solutions to SDD systems in time 
$\tilde{O}(m \log n \log (1/\epsilon) )$, where the $\tilde{O}$ notation hides 
a factor that is at most $(\log \log n)^2$. A highly readable account 
of SDD systems is the monograph by Vishnoi~\cite{Vis13}. We summarize the 
main result that we use as a black-box.  
\begin{proposition} \label{prop:SDD_systems} {\textrm{\cite{KMP11,Vis13}}}
	Given a system of linear equations $\mat{A} \vect{x} = \vect{b}$, where $\mat{A}$
	is an SDD matrix, there exists an algorithm to compute $\tilde{\vect{x}}$  
	such that:
		\[
			\norm{\tilde{\vect{x}} - \vect{x}}_{\mat{A}} \leq \epsilon \norm{\vect{x}}_{\mat{A}}, 
		\]
	where $\norm{\vect{y}}_{\mat{A}} := \sqrt{\trans{\vect{y}} \mat{A} \vect{y}}$. The algorithm runs in 
	time $\tilde{O}(m \cdot \log n \cdot \log (1 / \epsilon) )$ time, where $m$ is the number of non-zero 
	entries in $\mat{A}$. The $\tilde{O}$ notation hides a factor of at most $(\log \log n)^2$.
\end{proposition} 

%Given an $n \times n$ matrix~$\mat{A}$ and $\vect{b} \in \R^{n}$, consider the 
%system of linear equations $\mat{A} \vect{x} = \vect{b}$, with variables
%$\vect{x} = \trans{(x_1, \ldots, x_n)}$. Such a system has a solution if and only if
%$\vect{b}$ is in the image of matrix~$\mat{A}$. If $\mat{A}$ is invertible, then 
%the system has a solution for all $\vect{b} \in \R^n$. However, if $\vect{b}$ 
%is in the image of $\mat{A}$, then the inverse of $\mat{A}$ is well-defined 
%and is denoted by $\pseudo{\mat{A}}$. This is called the \emph{pseudo-inverse}
%of $\mat{D}$. 
%\begin{proposition} \label{prop:Laplacian_systems} {\textrm{\cite{ST08,Vis13}}}
%	There is an algorithm which takes a graph Laplacian $\mat{L}$, a vector 
%	$\vect{b}$, and an error parameter~$\epsilon > 0$, and returns $\vect{x}$
%	such that:
%		\[
%			\norm{\vect{x} - \pseudo{\mat{L}} \vect{b}}_{\mat{L}} \leq \epsilon \norm{\pseudo{\mat{L}} \vect{b}}_{\mat{L}}, 
%		\]
%	where $\norm{\vect{y}}_{\mat{L}} := \sqrt{\trans{\vect{y}} \mat{L} \vect{y}}$. The algorithm runs in 
%	time $O(m \cdot \log n \cdot \log 1 / \epsilon)$ time, where $m$ is the number of non-zero 
%	entries in $\mat{L}$.
%\end{proposition} 
%This result can be generalized to linear systems $\mat{A} \vect{x} = \vect{b}$, where 
%$\vect{b}$ is a symmetric (weakly) diagonally dominant matrix.

We can use Proposition~\ref{prop:SDD_systems} to upper-bound the time taken to 
calculate $\mat{N} \mat{R}$, where $\mat{N}$ is the fundamental matrix of the absorbing
Markov chain and $\mat{R}$ is as in equation~(\ref{eqn:canonical_form_P}).
\begin{lemma}\label{lemma:computing_NR}
Given a graph~$G$, let $\mat{P}$ be the $n \times n$ transition matrix in canonical form 
(see equation~(\ref{eqn:canonical_form_P})) defined by equations~(\ref{eqn:defining_prob_nonseed}) 
and~(\ref{eqn:defining_prob_seed}). Then one can compute 
the affinity vectors of all non-seed nodes in time $O(m \cdot \log n + ms + n)$ per community, 
where~$m$ is the number of edges in the graph~$G$ and $s$ is the number of seed nodes.
\end{lemma}  
\begin{proof}
Recall that we ordered the nodes of $G$ as $\{u_1, \ldots, u_{n - s}, x_1, \ldots, x_s\}$, 
where $u_1, \ldots, u_{n - s}$ denote the non-seed nodes and $x_1, \ldots, x_s$ denote 
seed nodes. Define $G_1 := G[u_1, \ldots, u_{n - s}]$, the subgraph induced by the non-seed nodes 
of~$G$. Let $\mat{A}_1$ denote the adjacency matrix of the graph $G_1$; let 
$\mat{D}_1$ denote the $(n - s) \times (n - s)$ diagonal matrix satisfying 
$\mat{D}_1(u_i, u_i) = \deg_{G}(u_i)$ for all $1 \leq i \leq n - s$.  That is, the 
entries of $\mat{D}_1$ are not the degrees of the vertices in the induced subgraph~$G_1$ 
but in the graph~$G$. We can then express 
$\mat{I} - \mat{Q}$ as 
\begin{equation} \label{eqn:I-Q}
	\mat{I}  - \mat{Q} = \inv{\mat{D}_1} (\mat{D}_1 - \mat{A}_1).
\end{equation}
Note that $\mat{D}_1 - \mat{A}_1$ is a symmetric and diagonally dominant matrix. 
Let us suppose that $\mat{X}$ is an $(n - s) \times s$ matrix such that 
\[
	\mat{X} = (\mat{I} - \mat{Q})^{-1} \cdot \mat{R}.
\]

Fix a community~$l$. Then the affinities of the non-seed nodes 
for community~$l$ may be written as:
\begin{align} \label{eqn:affinity}
	\left ( \begin{array}{c}
		\alpha (u_1, l) \\
		\vdots			\\
		\alpha (u_{n - s}, l)
	\end{array}	\right ) & = \sum_{j = 1}^{s} \alpha (x_j, l) \cdot \mat{X}_j \nonumber \\ 
						 & = \sum_{j = 1}^{s} \alpha (x_j, l) \inv{(\mat{I} - \mat{Q})} \cdot \mat{R}_j \nonumber \\ 
						 & = \inv{(\mat{I} - \mat{Q})} \cdot \sum_{j = 1}^{s} \alpha (x_j, l) \cdot \mat{R}_j,
\end{align}
where $\mat{X}_j$ and $\mat{R}_j$ denote the $j\th$ columns of $\mat{X}$ and $\mat{R}$, respectively. 
Using equation~(\ref{eqn:I-Q}), we may rewrite equation~(\ref{eqn:affinity}) as:
\begin{align}
	\inv{\mat{D}_1} (\mat{D}_1 - \mat{A}_1) \cdot \left ( \begin{array}{c}
		\alpha (u_1, l) \\
		\vdots			\\
		\alpha (u_{n - s}, l)
	\end{array}	\right ) & = \sum_{j = 1}^{s} \alpha (x_j, l) \cdot \mat{R}_j.
\end{align}
Finally, multiplying by $\mat{D}_1$ on both sides, we obtain
\begin{equation}\label{eqn:final_affinity}
	(\mat{D}_1 - \mat{A}_1) \cdot \vect{\alpha}_l = \mat{D}_1 \cdot \sum_{j = 1}^{s} \alpha (x_j, l) \cdot \mat{R}_j,
\end{equation}
where we used $\vect{\alpha}_l$ to denote the vector $\trans{\left ( \alpha (u_1, l), \ldots, \alpha (u_{n-s}, l) \right )}$.

Note that computing $\sum_{j = 1}^{s} \alpha (x_j, l) \cdot \mat{R}_j$ takes time $O(m \cdot s)$, where $m$ 
denotes the number of non-zero entries in $\mat{P}$. Computing the product of 
$\mat{D}_1$ and $\sum_{j = 1}^{s} \alpha (x_j, l) \cdot \mat{R}_j$ takes time $O(n)$ so that 
the right hand side of equation~\ref{eqn:final_affinity} can be computed in time $O(ms + n)$.
We now have a symmetric diagonally dominant system of linear equations which by 
Proposition~\ref{prop:SDD_systems} can be solved in time $O(m \cdot \log n)$. Therefore 
the time taken to compute the affinity to a fixed community is $O(m \cdot \log n + ms + n)$,
which is what was claimed. Since $m = O(n)$ and $s = O(\log n)$, the time taken 
is $O(n \cdot \log n)$ per community.  
%
%Then $(\mat{I} - \mat{Q}) \mat{X} = \mat{R}$, which may be rewritten as
%$(\mat{D}_1 - \mat{A}_1) \mat{X} = \mat{D}_1 \cdot \mat{R}$. The latter 
%equation may be written as a set of linear equation systems:
%\begin{equation}\label{eqn:laplacian_linear_eqn}
%	(\mat{D}_1 - \mat{A}_1) \cdot \vect{x}_i = \mat{D}_1 \cdot \vect{r}_i  \quad (\mbox{for } 1 \leq i \leq s),
%\end{equation} 
%where $\vect{x}_i$ and $\vect{r}_i$ are the $i\th$ columns of $\mat{X}$ and $\mat{R}$, respectively. 
%By Proposition~\ref{prop:SDD_systems}, the time taken to solve each of these systems 
%is $O(m \log n)$. Together, they can be solved in time $O(s \cdot m \cdot \log n)$, which
%is what was claimed.  
\end{proof}

\subsection{Some More Intuition}

Before we present our experimental results, it might be 
worthwhile to study how well our algorithm performs, at least in 
special cases.

Suppose that one of the communities in the network in question is $C_1$
which has $n_1$ nodes and $e_1$ internal edges (edges with both end-points within 
the community). Community $C_1$ is separated from the ``rest of the network,'' 
denoted $C_2$, by $e_3$ edges; that is, the cut $(C_1, C_2)$ has $e_3$ edges. 
We assume that $C_2$ has $n_2$ vertices and $e_2$ internal edges. Now $C_2$ 
could be a community in itself or a collection of communities. We wish to 
ascertain the probability with which a random walk starting at a randomly 
chosen node in $C_1$ ends up in a seed node for $C_1$. Assume that we 
pick a set $S_1$ of $s_1$ seed nodes from $C_1$ and a set $S_2$ of $s_2$ 
seed nodes from the rest of the graph, uniformly at random. We first want to 
estimate the probability that a randomly picked node~$u$ from $C_1$ transitions 
to one of the seed nodes in $S_1$ in \emph{one} step.

This could happen because~$u$ itself is a seed node, which happens with probability $s_1 / n_1$.
Next suppose that~$u$ does not have any neighbors in~$C_2$. If we denote the nodes 
of $C_1$ that do have a neighbor in~$C_2$ by $\partial C_1$, then the probability 
of a non-seed node in $C_1 - \partial C_1$ to transition in one step to a seed 
node in $S_1$ is:
\begin{equation}
    \frac{1}{d(u)} \cdot \sum_{x \in N(u)} \frac{s_1}{n_1} = \frac{s_1}{n_1}.
\end{equation}
Finally consider the case where~$u$ has a neighbor in $C_2$. The probability with 
which a randomly chosen node in $C_1$ transitions to a node in $C_1$ (in one step) is 
\[
    \frac{\mbox{average internal degree of a vertex in $C_1$}}
         {\mbox{total average degree of a vertex in $C_1$}},
\]
which works out to be 
\begin{equation}\label{exp:c1-c1}
    \frac{2e_1}{n_1} \div \frac{2e_1 + e_3}{n_1} = \frac{2e_1}{2e_1 + e_3}.
\end{equation}
The probability with which a randomly chosen node from $C_1$ makes a 
one-step transition to $C_2$ is 
\begin{equation}\label{exp:c1-c2}
    \frac{e_3}{2e_1 + e_3}.
\end{equation}
Therefore the probability with which a non-seed node in $\partial C_1$ 
transitions in one step to a seed node in $S_1$ is:
\begin{equation}
    \frac{2e_1 / n_1 }{2e_1 / n_1 + e_3 / |\partial C_1|} \cdot \frac{s_1}{n_1} 
        = \frac{2e_1}{2e_1 + e_3 \cdot (n_1 / |\partial C_1|)} \cdot \frac{s_1}{n_1}.
\end{equation}

Now we can write down the probability of a randomly picked 
node in $C_1$ transitioning in one step to a seed node in $S_1$
as:
\begin{equation}\label{exp:c1-s1}
    \frac{s_1}{n_1} +  \left ( 1 - \frac{|\partial C_1|}{n_1} \right ) \cdot \frac{s_1}{n_1} 
            + \frac{|\partial C_1|}{n_1} 
            \cdot \frac{2e_1}{2e_1 +e_3 \cdot ( n_1 /|\partial C_1 |)} 
            \cdot \frac{s_1}{n_1}.
\end{equation}
With a little algebraic manipulation, the above expression simplifies to: 
\begin{equation}\label{exp:final_c1-s1}
    \frac{s_1}{n_1} \cdot \left ( 2 - \frac{|\partial C_1|}{n_1} 
        \cdot \frac{e_3 \cdot 
        \frac{n_1}{|\partial C_1|}}{2e_1 + e_3 \cdot \frac{n_1}{|\partial C_1|}} \right ).
\end{equation}
Now the fractions $|\partial C_1| / n_1$ and 
$e_3 \cdot (n_1 / |\partial C_1|)/ (2e_1 + e_3 \cdot (n_1 / |\partial C_1|))$ 
are each at most one, so that their product is also at most one. Therefore, 
expression~(\ref{exp:final_c1-s1}) is at least $s_1/ n_1$ and 
at most $2s_1 / n_1$. We wish to keep things simple here and we 
choose to assign a probability of $s_1 / n_1$ to the event that 
a randomly chosen non-seed node in $C_1$ transitions to a seed node
in $S_1$ in one step.

Next note that the probability expression~(\ref{exp:c1-c1}) can be broken down 
into two events: the probability of transitioning to a seed node 
in $S_1$ (which is $s_1 / n_1$), and the probability of transitioning 
to a non-seed node in $C_1$, which then is:
\begin{equation}\label{exp:non_seed_c1}
    \frac{2e_1}{2e_1 + e_3} - \frac{s_1}{n_1}.
\end{equation}
By symmetry, the transition
probabilities of randomly picked node from $C_2$ are:
\begin{align}
    \mbox{to a seed node in $S_2$}      & = \frac{s_2}{n_2} \\
    \mbox{to a non-seed node in $C_2$}  & = \frac{2e_2}{2e_2 + e_3} - \frac{s_2}{n_2} \\
    \mbox{to a node in $C_1$}           & = \frac{e_3}{2e_2 + e_3}.
\end{align}
This gives rise to the four-state Markov chain depicted in Figure~\ref{fig:4stateMC}, 
where we used bars on $C_1$ and $C_2$ to denote the fact that these 
states represent the non-seed node counterparts of the respective node sets.
Note that the sum of the above three probabilities sum up to one, as they should.

We can now analyze the transition matrix of this absorbing Markov chain as 
before:
\begin{equation}\label{eqn:4-state-matrix}
    \mat{P} =
    \bordermatrix{\text{}   & \bar{C}_1 & \bar{C}_2 & S_1 & S_2 \cr
                  \bar{C}_1 & q_1       &  q_2      & r_1 & 0   \cr
                  \bar{C}_2 & q_3       &  q_4      &  0  & r_2 \cr
                        S_1 &  0        &   0       &  1  &  0  \cr
                        S_2 &  0        &   0       &  0  &  1},
\end{equation}
where we used $q_1, q_2, q_3, q_4, r_1, r_2$ to represent the respective 
probabilities that were calculated before. This matrix is in canonical form 
(see~\ref{eqn:canonical_form_P}) and the probabilities with which a non-seed 
node in $C_1$ and $C_2$ is absorbed in a seed node is given by the $2 \times 2$ matrix 
$\inv{(\mat{I} - \mat{Q})} \cdot \mat{R}$, which is:
\begin{equation}
    \inv{(\mat{I} - \mat{Q})} \cdot \mat{R} = \frac{1}{f(q_1, q_2, q_3, q_4)}
        \cdot \left ( \begin{matrix}
                            r_1 (1 - q_4) & r_2 q_2         \\  
                            r_1 q_3       & r_1 (1 - q_1)
                      \end{matrix} \right ),
\end{equation}
where $f(q_1, q_2, q_3, q_4) = (1 - q_1) (1 - q_4) - q_2 q_3$.

\begin{figure}[t]
\begin{center}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.8cm,
                    semithick]
  \tikzstyle{every state}=[text=black]

  \node[state]         (S1)               {$S_1$};
  \node[state]         (C1) [below of=S1] {$\bar{C}_1$};
  \node[state]         (S2) [right of=S1] {$S_2$};
  \node[state]         (C2) [below of=S2] {$\bar{C}_2$};

  \path (S1) edge [loop above]  node {$1$}                                        (S1)
        (C1) edge               node {$\frac{s_1}{n_1}$}                          (S1)
        (C1) edge [bend left]   node (dummy1) [above] {$\frac{e_3}{2e_1 + e_3}$}  (C2)
             edge [loop left]   node {$\frac{2e_1}{2e_1 + e_3} - \frac{s_1}{n_1}$} (C1)
        (C2) edge [bend left]   node (dummy2) [below] {$\frac{e_3}{2e_2 + e_3}$}  (C1)
             edge [loop right]  node {$\frac{2e_2}{2e_2 + e_3} - \frac{s_2}{n_2}$} (C2)
        (C2) edge               node {$\frac{s_2}{n_2}$}                          (S2)
        (S2) edge [loop above]  node {$1$}                                        (S2);
        
\end{tikzpicture}
\end{center}
\caption{The four-state Markov chain representing transitions for a random node.}
\label{fig:4stateMC}
\end{figure}

The probability of a random non-seed node of $C_1$ being absorbed by a 
seed node of $C_1$ is proportional to $r_1 (1 - q_4)$, which is: 
\begin{equation}\label{exp:prob_c1-s1}
    \frac{s_1}{n_1} \left ( \frac{e_3}{2e_2 + e_3} + \frac{s_2}{n_2} \right ).
\end{equation}
The probability of a random non-seed node of $C_1$ being absorbed by 
a seed node of $C_2$ is proportional to $r_2 q_2$, which is: 
\begin{equation}\label{exp:prob_c1-s2}
    \frac{s_2}{n_2} \cdot \frac{e_3}{2e_1 + e_3}.
\end{equation}
After a little manipulation, the ratio of the first expression~(\ref{exp:prob_c1-s1}) 
to the second~(\ref{exp:prob_c1-s2}) works out to:
\begin{equation} \label{exp:final_ratio}
    \frac{s_1}{n_1} \cdot \frac{2e_1 + e_3}{e_3} + 
    \frac{s_1}{n_1} \cdot \frac{n_2}{s_2} \cdot 
            \frac{2e_1 + e_3}{2e_2 + e_3}.
\end{equation}

Up till now, we have made no assumption about community structure. 
A commonly assumed structural characteristic is that communities 
are more dense inside than outside. \texttt{There are quite a few 
references that we ought to cite here.} We make this 
assumption now in order to make some sense of expression~(\ref{exp:final_ratio}).
Let us suppose that $C_1$ is ``clique-like'' so that $e_1 = \Omega(n_1^2)$ and 
that there are relatively few connections between it and the rest of the 
graph, which amounts to assuming that $e_3 = O(n_1)$. Then the first term 
of expression~(\ref{exp:final_ratio}) is $\Omega(s_1)$. The second 
term of this expression is harder to evaluate. If we assume that $C_2$ 
is also a clique-like community, then $e_2 = \Omega (n_2^2)$, in which 
case, the second term is $\Omega(s_1 n_1 /s_2 n_2)$ whose value 
depends on the relative community sizes. If, on the other hand, $C_2$ 
is a collection of several communities, we may continue to assume that 
it is sparse and hence $e_2 = O(n_2)$. The second term now is $\Omega(s_1 n_1 / s_2)$,
which is certainly large. The point is, irrespective of what $C_2$ constitutes, 
if $C_1$ is a dense-enough community it's non-seed nodes will tend to be absorbed
in $S_1$ rather than in $S_2$. We summarize this in the following theorem.
\begin{theorem}
    Let $G$ be a network and let $C_1, \ldots, C_k \subseteq G$ be the 
    communities in the network. For each community~$C_i$, we assume that 
    $E(C_i) = \Omega (n_i^2)$ and $E(C, G - C) = O(n_i)$, where $n_i := |V(C_i)|$.
    Further suppose that $s_i$ seed nodes are chosen uniformly at random from each 
    community $C_i$. Then a non-seed node picked u.a.r from~$C_i$ is absorbed 
    in a seed node of $C_i$ with a probability that is a factor $\Omega(s_i)$ 
    larger than the probability with which it is absorbed in the seed nodes 
    of the remaining communities.
\end{theorem}
