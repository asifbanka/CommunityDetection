\texttt{For some reason the figure references are broken.}

In this section we want to present the results for detecting non overlapping communities on the LFR benchmark. The results can be seen in Figures \ref{fig:no_iter_no_overlap}\ref{fig:iter_no_overlap}\ref{fig:compare_iter_no_overlap}. This is the simpler case of our tests because we now that a node is in exactly one community. The parameters of the LFR benchmark are chosen exactly as in \cite{LF09}, so that we are able to compare our results with those given by Lancichinetti and Fortunato. The average degree of the networks is $20$, the maximum degree $50$, the minus exponent of the degree distribution is $2$ and that of the community size distribution is $1$.

For our main test we distinguish between \textit{small} and \textit{big} community sizes, which vary between $10 - 50$ and $20 - 100$ nodes respectively. We have two network sizes that we investigate: $1000$ and $5000$ nodes. We have one setup for every of the four combinations of network and community sizes. For every setup we create graphs with those parameters and a varying mixing factor $\mu$ (the percentage of edges that are leaving the communities) and compare the results from our algorithm with the ground truth given by the benchmark using NMI (Normalized Mutual Information). Every point in the plot is the average over $100$ iterations using the same parameters. 

The benchmarks mentioned above are to compare our results with most of those mentioned in \cite{LF09}. The \textit{infomap} algorithm \cite{RB08} and the \textit{fast modularity optimization} \cite{BGLL08} however were also tested on much larger graphs.
Since our algorithm also runs in essentially linear time in the number of edges we replicated these tests, using graphs with $50000$ and $100000$ nodes. The maximum degree was set to $200$ and the communities vary between $20$ and $1000$.

Because our algorithm needs seed nodes as input, we have four plots per setup, using $5$, $10$, $15$ and $20$ percent of the nodes of the communities as seed nodes, which means we give the full community information provided by the LFR benchmark of these nodes as input. The percentages were chosen to show how much seed information is approximatively needed to get desirable results.

The first batch of benchmarks are those for the non iterative method, and can be seen in Figure \ref{fig:no_iter_no_overlap}. The first thing we notice is that five percent seed nodes are probably not sufficient to get desirable results, but if we get to at least ten percent we can, for a mixing factor of less or equal than $0.4$, already compete with \textit{infomap} which was deemed one the best performing algorithm on LFR graphs by \cite{LF09} and offer a discovery of communities with greater than $90$ percent accuracy. Above $0.4$ mixing factor we get worse get worse than \textit{infomod}, which is able to keep its performance at $100$ percent NMI till a mixing factor of around $0.6$ but then drops of pretty steep. Our drop begins more early but is not as steep.\texttt{having a comparative plot for infomod would be nice at this point.}

In Figure \ref{fig:iter_no_overlap} we show benchmarks for the iterative approach of our algorithm \texttt{I assume the iterative method was already introduced at this point}. When compared with the non iterative results, we can see that after ten iterations we already get a huge improvement (See Figure \ref{fig:compare_iter_no_overlap} for a direct comparison of the iterative method vs. non iterative). We can cut the amount of seed nodes in half and still get better results, if we use the iterative method. If we use the same number of seed nodes we can get NMI improvements as high as $60$ percent.